{"meta":{"title":"liiiyx's Blog","subtitle":"一如既往, 万事胜意 / 1024199338@qq.com","description":null,"author":"liiiyx","url":"http://yoursite.com"},"pages":[{"title":"关于","date":"2018-01-11T07:05:28.000Z","updated":"2018-01-11T07:06:31.023Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"Email：1024199338@qq.com PS：一只搞Android/爱摄影/爱模型的程序猿"}],"posts":[{"title":"多线程和虚拟机","slug":"多线程和虚拟机","date":"2018-01-12T02:56:01.000Z","updated":"2018-01-12T03:07:01.154Z","comments":true,"path":"2018/01/12/多线程和虚拟机/","link":"","permalink":"http://yoursite.com/2018/01/12/多线程和虚拟机/","excerpt":"之前在网上看到的一些关于虚拟机和线程的讲解，讲得比较的通俗易懂，在这里做个整理，方便以后查看。其实理解下来，这些信息都能联系到之前在大学上的操作系统这门课，虚拟机、线程、cpu运行等等，这样理解和延伸就变容易很多了。（现在很后悔当时没好好听课啊。。）","text":"之前在网上看到的一些关于虚拟机和线程的讲解，讲得比较的通俗易懂，在这里做个整理，方便以后查看。其实理解下来，这些信息都能联系到之前在大学上的操作系统这门课，虚拟机、线程、cpu运行等等，这样理解和延伸就变容易很多了。（现在很后悔当时没好好听课啊。。） 虚拟机Java程序运行在虚拟机上，而虚拟机又与操作系统打交道，最终通过二进制指令操纵电子电路运行，完成数据的读取、存储、运算和输出。 虚拟机在加载.class文件是，会在内存开辟一块区域“方法区”，专门用来存储类的基本信息，同时在“堆”区为这些类生成一个Class对象，作为类的镜像或模具，为反射提供基础。程序运行过程中，对象不断地生成和死亡，有的朝生暮死（大部分对象，例如方法内部生成的临时对象），有的壮年而亡，有的长命百岁，有的长生不死除非世界毁灭（虚拟机关闭）。对象生要吃喝死了要埋，所以虚拟机需要不停得去申请内存、回收内存。对象的生成方法有很多，new、反射等，对象回收的方法也很多，GC回收、标记-清除、复制、标记-整理等等。 垃圾回收，首先我们要知道什么是垃圾、为什么产生、如何回收。我所理解简单的垃圾回收，是后台启动一个线程，设置一定条件（间隔时间、资源阈值等），达到后扫描垃圾对象并清除，然后继续执行原来的程序。如果要更深层的研究，则需要考虑到效率、安全性等因素。举个例子： 对象生命周期不同，使用同一种回收机制（例如设置间隔时间）这样处理的效率是非常低的，对原程序的运行也会有不可预知的影响。那么我们可以这么改进： 根据对象的生命周期不同作为一个特性，用来划分不同的运行堆区，每个区采用不同的清理算法； 根据多核特性，启动多个回收线程一起跑； 由上述的内容，虚拟机优化就有两个大方向：各个区的大小如何最优划分、GC回收算法如何选择最优，映射到技术层面就是JVM参数调整。 多线程程序运行的时候，占有cpu和内存资源，而cpu运算的时候需要从内存（很多时候是缓存）取值，然后放入寄存器参与运算，得到结果后先放入寄存器，再放回内存。程序执行的指令集也在放在寄存器中，它记录了当前程序执行的地址。一句话概括就是：程序=数据结构+算法。 线程执行是语言指令寄存器的，也就是当你切换线程的时候，需要从虚拟机的程序计数器（PC）把该线程的执行指令放到寄存器，当然线程涉及的其他资源也要切换，例如IO设备。这些都是需要耗费资源的，也就是常说的线程的上下文切换。cpu在执行程序的时候，需要准备程序执行指令所需的寄存器的值，以及所涉及的设备（文件系统、网络资源等），所以说线程创建是一个很大的开销，这也就解释了线程是cpu执行的最小单位了。 延伸一个问题，为什么单线程比多线程快？如上所述线程创建时cpu会分配资源，切换线程时其他资源也需要切换，在单线程模式下，资源都是线程本身的，不存在与其他线程共享与竞争其他资源的情况。 Java Thread的start方法和run方法的区别由上述关于多线程的内容可知，start方法会在线程开始执行的时候准备线程所需的资源，而run方法则是相当于普通的方法调用，程序依然运行在主线程中。因此在多线程应用中，调用start方法后，线程必须的资源虚拟机会自动分配，我们所需要关心的只是告诉线程我们想做什么。 从此我们可以延伸出实现线程的方式： 继承Thread，重写run方法； 实现Runnable接口，实现run方法； 实现Callable接口，回调获取线程结果； 方法1使用了继承，方法2、3使用了组合，内部持有了所需实现的类，会让程序更加灵活。（这里可以对应到“多用组合少用继承”的开发原则）。 synchronized关键字与同步机制一个数值，进入cpu运算，需要经过内存-&gt;多级缓存-&gt;寄存器。当多线程运算同一个数值是，需要把值从主内存拿到该线程工作的内存单元（寄存器）中，当一个线程计算完毕（CPU会优先把计算结果放到寄存器），还没来得及将数值刷新到主内存，这时候其他线程从主内存取到的是旧值。JVM运行的每个线程都有自己的线程栈，不同线程运行时，都需要复制主内存的一份副本到自身的工作内存。如何保证每个线程拿到的数据都是最新的，这就是同步机制。 synchronized关键字就是给数据上个锁，共享变量同一时刻只允许一个线程去操作，其他线程必须等待锁释放后才可以进入。这里可以联系到上厕所模型，然后就可以延伸出锁的类型了。 但有些时候，我们不关心共享值在被谁操作，我们只关心这个值当前是什么。所以就有了volatile。很多博客对该关键词的描述是：保证可见性，不保证原子性。我们来拆解（拆分理解）一下这句话。 一个共享变量声明为volatile，等于告诉虚拟机控制所有的线程：这个变量有点帅，要请他需要他的老家（主内存）来，回来时也要尽快送回去。所以，CPU计算时从主内存取值，计算完毕后直接存入主内存，不会写到缓存了。这就是所谓的“可见性”，这个值当前是什么，我们是完全知道的。至于原子性，由上可知谁都可以取值来进行运算。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"}]},{"title":"Camera1架构和ASD流程源码分析","slug":"Camera1架构和ASD流程源码分析","date":"2018-01-12T01:46:32.000Z","updated":"2018-01-12T01:51:19.512Z","comments":true,"path":"2018/01/12/Camera1架构和ASD流程源码分析/","link":"","permalink":"http://yoursite.com/2018/01/12/Camera1架构和ASD流程源码分析/","excerpt":"","text":"相关文件路径 Java层:/vendor/mediatek/proprietary/packages/apps/Camera/src/ /com/mediatek/camera/AdditionManager.java /com/mediatek/camera/addition/Asd.java /com/android/camera/CameraManager.java /com/android/camera/AndroidCamera.java framework层：/frameworks/av/camera/Camera.cpp/frameworks/av/camera/CameraBase.cpp/frameworks/av/services/camera/libcameraservice/api1/CameraClient.cpp/frameworks/av/services/camera/libcameraservice/mediatek/api1/CameraClient.cpp/frameworks/base/core/java/android/hardware/Camera.java jni层： /frameworks/base/core/jni/android_hardware_Camera.cpp Hardware层：vendor/mediatek/proprietary/hardware/mtkcam/ legacy/platform/mt6735/core/featureio/pipe/aaa/Hal3AAdapter1.cpp legacy/platform/mt6735/core/featureio/pipe/asd/asd_hal_base.cpp legacy/platform/mt6735/core/featureio/pipe/asd/asd/asd_hal.cpp legacy/platform/mt6735/v1/client/CamClient/FD/Asd/AsdClient.cpp legacy/platform/mt6735/v1/client/CamClient/FD/FDClient.Thread.cpp main/hal/device1/common/Cam1DeviceBase.cpp legacy/v1/client/CamClient/CamClient.cpp 1. 引言最近遇到了ASD(自动场景检测)在室内光线较好的情况下，会选择到夜间模式，需要调整其阈值。于是分析了MTK平台对于Camera1架构的源码实现流程，梳理了ASD的工作流程(App-&gt;framework-&gt;jni-&gt;HAL)，但也仅是对源码流程的一个贯穿，没有对具体实现深入分析。以后若有时间进一步学习，再做补充。 分析思路： 先以设置里打开ASD开关为触发点，预览界面/场景检测结果更新为截止点，抓取camera的mtklog； 检索log的关键信息，找到App层的入口，分析在上层及framework层所做的操作； 检索log的关键信息，找到HAL层的入口，分析在HAL层的事件处理以及消息传递； 结合2和3的分析结果，分析framework层与HAL层的jni通信； 2. 架构camera架构图如下： 应用框架应用代码位于应用框架级别，它利用 android.hardware.Camera API 来与相机硬件互动。在内部，此代码会调用相应的 JNI 粘合类，以访问与该相机互动的原生代码。 JNI与 android.hardware.Camera 关联的 JNI 代码位于 frameworks/base/core/jni/android_hardware_Camera.cpp。此代码会调用较低级别的原生代码以获取对物理相机的访问权限，并返回用于在框架级别创建 android.hardware.Camera 对象的数据。 原生框架在 frameworks/av/camera/Camera.cpp 中定义的原生框架可提供相当于 android.hardware.Camera 类的原生类。此类会调用 IPC binder 代理，以获取对相机服务的访问权限。 Binder IPC 代理IPC binder 代理有助于越过进程边界实现通信。调用相机服务的 frameworks/av/camera 目录中有 3 个相机 binder 类。ICameraService 是相机服务的接口，ICamera 是已打开的特定相机设备的接口，ICameraClient 是返回应用框架的设备接口。 相机服务位于 frameworks/av/services/camera/libcameraservice/CameraService.cpp 下的相机服务是与 HAL 进行互动的实际代码。 HAL硬件抽象层定义了由相机服务调用且您必须实现以确保相机硬件正常运行的标准接口。 内核驱动程序相机的驱动程序可与实际相机硬件和您的 HAL 实现进行互动。相机和驱动程序必须支持 YV12 和 NV21 图片格式，以便在显示和视频录制时支持预览相机图片。 以上信息引用自：https://source.android.com/devices/camera/ 。接下来顺着Camera1的纵线流程来分析MTK平台上ASD是如何工作的。 3. 启动流程(App、Framework层)3.1 启动流程图 接下来，从源码来说说这个流程图。 3.2 AdditionManager.java1234567891011121314151617181920public void onCameraParameterReady(boolean isMode) &#123; // 参数变化时会调用到这里 Log.i(TAG, &quot;[onCameraParameterReady]isMode = &quot; + isMode); Vector&lt;ICameraAddition&gt; curAddition = mModeAddition; if (!isMode) &#123; curAddition = mNormalAddition; &#125; for (ICameraAddition addition : curAddition) &#123; // Asd继承自CameraAddition // 在这里判断Asd开关是否支持&amp;打开 boolean isSupport = addition.isSupport(); boolean isOpen = addition.isOpen(); if (isSupport &amp;&amp; !isOpen) &#123; // 如果支持且开关已打开，则调用Asd的open方法打开Asd模式 addition.open(); &#125; else if (!isSupport &amp;&amp; isOpen) &#123; addition.close(); &#125; &#125;&#125; 3.3 Asd.java12345678910111213141516171819@Overridepublic void open() &#123; Log.d(TAG, &quot;[open]...&quot;); startAsd();&#125;public void startAsd() &#123; Log.i(TAG, &quot;[startAsd]...&quot;); // 更新当前camera设备实例 updateCameraDevice(); if (mICameraDevice == null) &#123; return; &#125; // 这里通知framework层做Asd Callback的初始化和设置 // 用来接收来自HAL层的消息 mICameraDevice.setAsdCallback(mASDCaptureCallback); // 更新ASD状态 mCurrentState = AsdState.STATE_OPENED;&#125; 3.4 CameraManager.java1234567891011121314151617181920212223@Overridepublic void setAsdCallback(AsdListener asdListener) &#123; // 创建AsdListener实例 mCameraDevice.setAsdCallback(asdListener == null ? null : new AsdListenerImpl(asdListener));&#125;public void setAsdCallback(AsdCallback asdCallback) &#123; // 通知内部类CameraHandler，设置AsdCallback mCameraHandler.obtainMessage(SET_ASD_CALLBACK, asdCallback).sendToTarget(); waitDone();&#125;private class CameraHandler extends Handler &#123; @Override public void handleMessage(final Message msg) &#123; ... case SET_ASD_CALLBACK: // 这里mCamera是ICamera实例，接口在AndroidCamera中实现 mCamera.setAsdCallback((AsdCallback) msg.obj); return; ... &#125;&#125; 3.5 AndroidCamera.java1234public void setAsdCallback(AsdCallback cb) &#123; // 调用Camera1接口设置Asd的回调 mCamera.setAsdCallback(cb);&#125; 3.6 android.hardware.Camera.java1234567891011/** * @hide * @internal * * Registers a callback to be invoked when auto scene is detected * @param cb the callback to run */public final void setAsdCallback(AsdCallback cb) &#123; // 设置framework层的AsdCallback回调实例 mAsdCallback = cb;&#125; 3.7 AsdCallback的创建12345678910111213141516// Asd.java的内部类，实现了AsdListener接口// 用于接收来自HAL层的消息，然后通知camera ui做出相应处理private final AsdListener mASDCaptureCallback = new AsdListener() &#123; public void onDeviceCallback(int scene) &#123; Log.i(TAG, &quot;[onDeviceCallback] onDetected scene = &quot; + scene + &quot;,&quot; + &quot;mLastScene:&quot; + mLastScene); if (mLastScene != scene) &#123; boolean suggestedHdr = (scene == SCENE_BACK_LIGHT || scene == SCENE_BACK_LIGHT_PORTRAIT); // 通知camera ui场景的选择结果 mICameraAppUi.onDetectedSceneMode(scene, suggestedHdr); mLastScene = scene; &#125; &#125;&#125;; 4. 处理流程及消息回调(Hardware层)下面主要讲述在Hardware层，Asd是如何初始化其Client，然后根据camera设备提供的信息进行场景选择，将结果返回给framework层的Camera1，随后传递到上层Camera app的。首先来看看流程图。 4.1 处理流程图 4.2 Hardware层文件说明 FDClient、AsdClient.cpp : Camera的每个feature好像都有一个专属的Client，每个Client又有专属的Client.Thead线程用来处理各类事件；而Asd的场景列表中有人脸模式（在后续的scene decider时也传入了facenum这样的参数）。这里没有进行深入研究，这里就先暂不拓展，因为整个camera架构还是很大的Orz asd_hal.cpp : 该流程的核心成员，主要功能是halASD实例的创建与销毁、ASD的初始化、场景选择。MTK在这里进行ASD各场景的阈值设置，同时分离了一个客制化的配置文件camera_custom_asd.h，客户可在HalAsdInit初始化的时候读取该客制化文件的值，从而客制化修改ASD场景的阈值； CameraClient.cpp : 用以接收来自AsdClient的回调消息； Camera.cpp : 上报回调消息到jni层； android_hardware_Camera.cpp : jni层的实现 4.3 FD.Client.Thread.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// PreviewClient的state发生变化时会发送eID_WAKEUP消息// FDClient应该也会接收到，这里没去细看bool FDClient::threadLoop()&#123; Command::EID cmd; if ( getCommand(cmd) ) &#123; switch (cmd) &#123; case Command::eID_WAKEUP: // 初始化一些Client onClientThreadLoop(); break; // case Command::eID_EXIT: default: MY_LOGD(&quot;Command::%d&quot;, cmd); break; &#125; &#125; ...&#125;void FDClient::onClientThreadLoop()&#123; ... #if (1 == AUTO_SCENE_DETECT_SUPPORT) //ASD Init // 创建AsdClient实例 mpASDClient = IAsdClient::createInstance(mpParamsMgr); // 调用AsdClient的init方法初始化AsdClient if ( mpASDClient == 0 || ! mpASDClient-&gt;init() ) &#123; MY_LOGE(&quot;mpASDClient init failed&quot;); &#125; // 设置回调 mpASDClient-&gt;setCallbacks(mpCamMsgCbInfo); #endif //(3) Do in loop until stopFaceDetection has been called // either by sendCommand() or by stopPreview() while ( isEnabledState() ) &#123; ... if (mpFDHalObj != NULL) &#123; // (3.4) //performCallback(isDetected_FD, isDetected_SD); performCallback(isDetected_FD, isDetected_SD, isDetected_GD); #if (1 == AUTO_SCENE_DETECT_SUPPORT) //Call ASD if doFD if(isMsgEnabled()) &#123; int FaceNum = mpFDHalObj-&gt;halFDGetFaceResult(mpDetectedFaces); // 进行更新操作 // 这里开始进入到AsdClient的流程(场景选择/消息回调) mpASDClient-&gt;update(DDPBuffer, srcWidth, srcHeight, FaceNum); &#125; #endif &#125; ... &#125; ... #if (1 == AUTO_SCENE_DETECT_SUPPORT) if (mpASDClient != 0) &#123; mpASDClient-&gt;uninit(); mpASDClient = NULL; &#125; #endif ...&#125; 4.4 AsdClient.cpp12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788voidAsdClient::update(MUINT8 * OT_Buffer, MINT32 a_Buffer_width, MINT32 a_Buffer_height, MINT32 a_FaceNum)&#123; MUINT32 u4Scene = 0; ASDInfo_T ASDInfo; bool const isAsdEnabled = mpParamsMgr-&gt;getShotModeStr() == MtkCameraParameters::CAPTURE_MODE_ASD_SHOT; enable(isAsdEnabled); if ( ! isEnabled() ) &#123; return; &#125; //Get 3A Info. MINT32 const i4SensorDevId = 1; //Need to be fixed. i4SensorDevId--&gt; i4SensorDevIdIndex, BinChang 2014/01/13 // 创建一个Hal3AAdapter实例，用以获取ASDInfo mpHal3A = IHal3A::createInstance(NS3A::IHal3A::E_Camera_1, mpParamsMgr-&gt;getOpenId(), LOG_TAG); mpHal3A-&gt;getASDInfo(ASDInfo); if (mpHal3A) &#123; mpHal3A-&gt;destroyInstance(LOG_TAG); &#125; //Get FD Info.#if(0) mpHalFD = halFDBase::createInstance(HAL_FD_OBJ_FDFT_SW); mpHalFD-&gt;halFDGetFaceInfo(mpFaceInfo); if(mpHalFD) &#123; mpHalFD-&gt;destroyInstance(); &#125;#endif //Asd Pipe Init. // 初始化Asd管道 if(mpHalASDObj == NULL) &#123; //Set Frame: Prepare QVGA RGB565 resolution if(a_Buffer_width*3 == a_Buffer_height*4) Buffer_height = 240; else if(a_Buffer_width*9 == a_Buffer_height*16) Buffer_height = 180; else if(a_Buffer_width*3 == a_Buffer_height*5) Buffer_height = 192; else Buffer_height = 240; // 创建halAsd实例 mpHalASDObj = halASDBase::createInstance(HAL_ASD_OBJ_AUTO); if(mpHalASDObj == NULL) &#123; MY_LOGE(&quot;mpHalASDObj createInstance fail&quot;); &#125; // 初始化halAsd实例，这里传入了一个ASDInfo，里面是AWB的一些信息 // 参数的客制化修改也是在这里进行 mpHalASDObj-&gt;mHalAsdInit((void*)&amp;ASDInfo, mpWorkingBuf, (eSensorType==SENSOR_TYPE_RAW)?0:1, Buffer_width/2, Buffer_height/2); &#125; //Asd Pipe Decider // 开始场景检测，这里交由mtk封装的camera算法lib库文件处理，结果是返回到mSceneCur // 注意这里还传入了一个参数a_FaceNum，所以说FDClient跟AsdClient是有关联的 mpHalASDObj-&gt;mHalAsdDecider((void*)&amp;ASDInfo, a_FaceNum ,mSceneCur); //MY_LOGD(&quot;ASDInfo.bAEBacklit:%d &quot;, ASDInfo.bAEBacklit); //MY_LOGD(&quot;mSceneCur:%d &quot;, mSceneCur); u4Scene = mSceneCur; MY_LOGD(&quot;u4Scene:%d &quot;, u4Scene); if (1) &#123; // 消息处理，通知回调函数 // 这里的mNotifyDb回调函数是在CameraClient的initialize函数里设置了 // 对应CameraClient的notifyCallback函数，下面的CameraClient章节会说明一下这部分 mpCamMsgCbInfo-&gt;mNotifyCb( MTK_CAMERA_MSG_EXT_NOTIFY, //msgType MTK_CAMERA_MSG_EXT_NOTIFY_ASD, //ext1 u4Scene, //ext2 mpCamMsgCbInfo-&gt;mCbCookie ); &#125; //MY_LOGD(&quot;Buffer_width:%d, Buffer_height:%d,&quot;, Buffer_width, Buffer_height); // 场景选择后的处理，这里主要是做了一些缓存区的申请 mpHalASDObj-&gt;mHalAsdDoSceneDet((void*)OT_Buffer, Buffer_width, Buffer_height);&#125; 4.5 asd_hal.cppAsd初始化： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364MINT32 halASD::mHalAsdInit(void* AAAData,void* working_buffer,MUINT8 SensorType, MINT32 Asd_Buf_Width, MINT32 Asd_Buf_Height)&#123; ASD_Customize_PARA1 ASDThres1; //客制化参数集1 ASD_Customize_PARA2 ASDThres2; //客制化参数集2 g_udCount++; MY_LOGD(&quot;[halASD] g_udCount++:%d \\n&quot;, g_udCount); AAA_ASD_PARAM* rASDInfo=(AAA_ASD_PARAM*)AAAData; MINT32 Retcode = S_ASD_OK; MUINT32* AFtable=(MUINT32*)malloc((rASDInfo-&gt;i4AFTableIdxNum + 1)*sizeof(MUINT32)); // debug开关，可通过设置property来打开，从而查看更多log信息 char value[PROPERTY_VALUE_MAX] = &#123;&apos;\\0&apos;&#125;; property_get(&quot;ASD.debug.dump&quot;, value, &quot;0&quot;); mHalASDDumpOPT = atoi(value); gMyAsdInitInfo.pInfo = &amp;gMyAsdEnvInfo; gMyAsdInitInfo.pDeciderInfo = &amp;gMyDeciderEnvInfo; gMyAsdInitInfo.pDeciderTuningInfo = &amp;gMyDeciderTuningInfo; ... //这里省略的代码是做gMyAsdInitInfo的一些初始化操作，其中比较关键的是pDeciderInfo的初始化 //主要是3A中的AWB、AF信息的获取和赋值 ... //这里将pDeciderInfo的指针地址赋值为0了，使用mtk camera算法底层库的默认册数 //如果需要对ASD的的参数进行客制化修改，需要注释掉这里 //不然在客制化赋值的时候会找不到正确的内存地址，而导致修改无效 gMyAsdInitInfo.pDeciderTuningInfo = 0; // use default value ... /* Create MTKPano Interface */ //m_pMTKAsdObj用于调用底层库方法 if(m_pMTKAsdObj == NULL) &#123; m_pMTKAsdObj = MTKAsd::createInstance(DRV_ASD_OBJ_SW); MY_LOGW_IF(m_pMTKAsdObj == NULL, &quot;Err&quot;); &#125;//客制化参数的获取和设置//if (0)默认不编译，如果需要进行客制化修改，这里需要改成if (1)#if (0) //从camera_custom.h中获取客制化参数集 get_asd_CustomizeData1(&amp;ASDThres1); get_asd_CustomizeData2(&amp;ASDThres2); //客制化参数设置 gMyAsdInitInfo.pDeciderTuningInfo-&gt;IdxWeightBlAe = ASDThres2.s2IdxWeightBlAe; ... gMyAsdInitInfo.pDeciderTuningInfo-&gt;EvLoThrNight = ASDThres2.s2EvLoThrNight; gMyAsdInitInfo.pDeciderTuningInfo-&gt;EvHiThrNight = ASDThres2.s2EvHiThrNight; ... gMyAsdInitInfo.pDeciderTuningInfo-&gt;ScoreThrNight = ASDThres1.u1ScoreThrNight; ...#endif //初始化Asd m_pMTKAsdObj-&gt;AsdInit(&amp;gMyAsdInitInfo, 0); if (AFtable) &#123; free(AFtable); &#125; return Retcode;&#125; Asd场景检测：123456789101112131415161718192021222324252627MINT32 halASD::mHalAsdDecider(void* AAAData,MINT32 Face_Num,mhal_ASD_DECIDER_UI_SCENE_TYPE_ENUM &amp;Scene)&#123; MINT32 Retcode = S_ASD_OK; AAA_ASD_PARAM* rASDInfo=(AAA_ASD_PARAM*)AAAData; ASD_DECIDER_RESULT_STRUCT MyDeciderResult; ASD_SCD_RESULT_STRUCT gMyAsdResultInfo; ASD_DECIDER_INFO_STRUCT gMyDeciderInfo; ... //设置gMyDeciderInfo的Fd(人脸检测)、3A(AE&amp;AWB&amp;AF)信息 ... // 这里的m_pMTKAsdObj在Asd init的时候创建了，用以调用MTK底层库封装的函数 // AsdFeatureCtrl、AsdMain这两个函数的实现是在/vendor/xxx/libs中 // 可以通过 grep 关键字 来检索 m_pMTKAsdObj-&gt;AsdFeatureCtrl(ASD_FEATURE_GET_RESULT, 0, &amp;gMyAsdResultInfo); memcpy(&amp;(gMyDeciderInfo.InfoScd),&amp;gMyAsdResultInfo, sizeof(ASD_SCD_RESULT_STRUCT)); m_pMTKAsdObj-&gt;AsdMain(ASD_PROC_DECIDER, &amp;gMyDeciderInfo); m_pMTKAsdObj-&gt;AsdFeatureCtrl(DECIDER_FEATURE_GET_RESULT, 0, &amp;MyDeciderResult); MY_LOGD(&quot;[mHalAsdDecider] detect Scene is %d, Face Num:%d \\n&quot;,MyDeciderResult.DeciderUiScene, gMyDeciderInfo.InfoFd.FdFaceNum); // 得到场景检测的结果 Scene=(mhal_ASD_DECIDER_UI_SCENE_TYPE_ENUM) MyDeciderResult.DeciderUiScene; //Scene=mhal_ASD_DECIDER_UI_AUTO; return Retcode;&#125; 4.6 CameraClient.cpp首先先来说说AsdClient中提到的mNotifyCb函数，这个函数是在CameraClient的initialize函数中被定义的。我们来看看代码：1234567891011status_t CameraClient::initialize(CameraModule *module) &#123; ... mHardware = new CameraHardwareInterface(camera_device_name); ... //调用的是Cam1DeviceBase的setCallback()函数 mHardware-&gt;setCallbacks(notifyCallback, dataCallback, dataCallbackTimestamp, (void *)(uintptr_t)mCameraId); ...&#125; 接下来我们看看Cam1DeviceBase setCallback函数的实现： 1234567891011121314151617181920212223242526272829303132// Set the notification and data callbacksvoid Cam1DeviceBase::setCallbacks( camera_notify_callback notify_cb, //notify Callback函数 camera_data_callback data_cb, //data Callback函数 camera_data_timestamp_callback data_cb_timestamp, camera_request_memory get_memory, void*user)&#123; mpCamMsgCbInfo-&gt;mCbCookie = user; mpCamMsgCbInfo-&gt;mNotifyCb = notify_cb; //mNotifyCb函数赋值 mpCamMsgCbInfo-&gt;mDataCb = data_cb; //mDataCb函数赋值 mpCamMsgCbInfo-&gt;mDataCbTimestamp= data_cb_timestamp; mpCamMsgCbInfo-&gt;mRequestMemory = get_memory; // if ( mpCamClient != 0 ) &#123; mpCamClient-&gt;setCallbacks(mpCamMsgCbInfo); &#125; // forward to registered clients Vector&lt;sp&lt;ICamClient&gt; &gt;::const_iterator it; for (it = vmpCamClient.begin(); it != vmpCamClient.end(); ++it) &#123; (*it)-&gt;setCallbacks(mpCamMsgCbInfo); &#125; // if ( mpCamAdapter != 0 ) &#123; mpCamAdapter-&gt;setCallbacks(mpCamMsgCbInfo); &#125;&#125; 刚才我们分析到AsdClient在进行场景检测得到结果后，调用了mNotifyCb函数；根据上面的分析，mNotifyCb函数指向CameraClient的notifyCallback函数，来看看该函数的代码： 1234567891011121314151617181920212223242526272829303132333435363738// Callback messages can be dispatched to internal handlers or pass to our// client&apos;s callback functions, depending on the message type.//// notifyCallback:// CAMERA_MSG_SHUTTER handleShutter// (others) c-&gt;notifyCallback// dataCallback:// CAMERA_MSG_PREVIEW_FRAME handlePreviewData// CAMERA_MSG_POSTVIEW_FRAME handlePostview// CAMERA_MSG_RAW_IMAGE handleRawPicture// CAMERA_MSG_COMPRESSED_IMAGE handleCompressedPicture// (others) c-&gt;dataCallback// dataCallbackTimestamp// (others) c-&gt;dataCallbackTimestampvoid CameraClient::notifyCallback(int32_t msgType, int32_t ext1, int32_t ext2, void* user) &#123; LOG2(&quot;notifyCallback(%d)&quot;, msgType); sp&lt;CameraClient&gt; client = static_cast&lt;CameraClient*&gt;(getClientFromCookie(user).get()); if (client.get() == nullptr) return; if (!client-&gt;lockIfMessageWanted(msgType)) return; switch (msgType) &#123; //!++ case MTK_CAMERA_MSG_EXT_NOTIFY: client-&gt;handleMtkExtNotify(ext1, ext2); // Callback extended msg notification. break; //!-- case CAMERA_MSG_SHUTTER: // ext1 is the dimension of the yuv picture. client-&gt;handleShutter(); break; default: client-&gt;handleGenericNotify(msgType, ext1, ext2); break; &#125;&#125; mNotifyCb函数调用传入的msgType是MTK_CAMERA_MSG_EXT_NOTIFY ，那么接下来会执行到handleMtkExtNotify，该函数在Mediatek自己写的CameraClient.cpp中实现。12345678910111213141516171819202122232425262728void CameraClient::handleMtkExtNotify(int32_t ext1, int32_t ext2)&#123; int32_t const extMsgType = ext1; switch (extMsgType) &#123; case MTK_CAMERA_MSG_EXT_NOTIFY_CAPTURE_DONE: handleMtkExtCaptureDone(ext1, ext2); break; // case MTK_CAMERA_MSG_EXT_NOTIFY_SHUTTER: handleMtkExtShutter(ext1, ext2); break; // case MTK_CAMERA_MSG_EXT_NOTIFY_BURST_SHUTTER: handleMtkExtBurstShutter(ext1, ext2); break; case MTK_CAMERA_MSG_EXT_NOTIFY_CONTINUOUS_SHUTTER: handleMtkExtContinuousShutter(ext1, ext2); break; case MTK_CAMERA_MSG_EXT_NOTIFY_CONTINUOUS_END: handleMtkExtContinuousEnd(ext1, ext2); break; // default: handleGenericNotify(MTK_CAMERA_MSG_EXT_NOTIFY, ext1, ext2); break; &#125;&#125; 传入的ext1为MTK_CAMERA_MSG_EXT_NOTIFY_ASD，所以又走回Android原生 CameraClient 的handleGenericNotify函数：1234567891011121314151617181920212223242526void CameraClient::handleGenericNotify(int32_t msgType, int32_t ext1, int32_t ext2) &#123; //!++ #ifdef MTK_CAM_FRAMEWORK_DEFAULT_CODE //!-- sp&lt;hardware::ICameraClient&gt; c = mRemoteCallback; //!++ #else sp&lt;hardware::ICameraClient&gt; c; &#123; Mutex::Autolock remoteCallbacklock(mRemoteCallbackLock); c = mRemoteCallback; &#125; #endif //!-- //!++ There some dead lock issue in camera hal, so we need to disable this function before all dead lock issues hase been fixed. #ifdef MTK_CAM_FRAMEWORK_DEFAULT_CODE mLock.unlock(); #endif //!-- // 除了notifyCallback这种方式，在看Preview流程时还有一种方式是 // copy当前帧然后把copy后的数据直接发送出去 if (c != 0) &#123; c-&gt;notifyCallback(msgType, ext1, ext2); &#125;&#125; 由上可知消息是通过12sp&lt;hardware::ICameraClient&gt; c = mRemoteCallback; c-&gt;notifyCallback(msgType, ext1, ext2); 的方式发送出去的。 那这个mRemoteCallback又是在哪里初始化的呢？检索了一下，是在CameraClient::connect中被赋值了，继续跟踪下去，会发现是在CameraClient的构造函数里初始化的，这里涉及到了多层继承(CameraClient-&gt;CameraService-&gt;Client)，看看代码：1234567891011121314151617181920212223242526272829303132333435step1：CameraClient::CameraClient(const sp&lt;CameraService&gt;&amp; cameraService, const sp&lt;hardware::ICameraClient&gt;&amp; cameraClient, // 这里传入了一个ICameraClient const String16&amp; clientPackageName, int cameraId, int cameraFacing, int clientPid, int clientUid, int servicePid, bool legacyMode): // 这里开始调用Client的构造函数，传入一个cameraClient参数 // Client是CameraService底下的一个内部类 Client(cameraService, cameraClient, clientPackageName, cameraId, cameraFacing, clientPid, clientUid, servicePid) step2：CameraService::Client::Client(const sp&lt;CameraService&gt;&amp; cameraService, const sp&lt;ICameraClient&gt;&amp; cameraClient, const String16&amp; clientPackageName, int cameraId, int cameraFacing, int clientPid, uid_t clientUid, int servicePid) : CameraService::BasicClient(cameraService, IInterface::asBinder(cameraClient), clientPackageName, cameraId, cameraFacing, clientPid, clientUid, servicePid)&#123; int callingPid = getCallingPid(); LOG1(&quot;Client::Client E (pid %d, id %d)&quot;, callingPid, cameraId); // 这里对mRemoteCallback进行了赋值初始化 mRemoteCallback = cameraClient; cameraService-&gt;loadSound(); LOG1(&quot;Client::Client X (pid %d, id %d)&quot;, callingPid, cameraId);&#125; 那么思路就清晰了，我们只需要看一下这个CameraClient进行了初始化就可以了。从Camera的connect方法看一下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253step 1：sp&lt;Camera&gt; Camera::connect(int cameraId, const String16&amp; clientPackageName, int clientUid, int clientPid)&#123; // CameraBaseT在CameraBase中被定义：typedef CameraBase&lt;TCam&gt; CameraBaseT // CameraBase在Camera被初始化为CameraBase&lt;Camera&gt;，所以上面就相应于调用了 // CameraBase&lt;Camera&gt;::connect() return CameraBaseT::connect(cameraId, clientPackageName, clientUid, clientPid);&#125;step 2：template &lt;typename TCam, typename TCamTraits&gt;sp&lt;TCam&gt; CameraBase&lt;TCam, TCamTraits&gt;::connect(int cameraId, const String16&amp; clientPackageName, int clientUid, int clientPid)&#123; ALOGV(&quot;%s: connect&quot;, __FUNCTION__); // 构造Camera实例 sp&lt;TCam&gt; c = new TCam(cameraId); // TCamCallbacks在Camera.h中被定义为ICameraClient // 这里cl = c被赋值为Camera类型，而Camera继承了ICameraClient sp&lt;TCamCallbacks&gt; cl = c; const sp&lt;::android::hardware::ICameraService&gt; cs = getCameraService(); binder::Status ret; if (cs != nullptr) &#123; // fnConnectService在Camera被初始化为ICameraService::connect() TCamConnectService fnConnectService = TCamTraits::fnConnectService; // 这里调用了CameraService::connect() c和cl是同一个值，做为两个不同的参数传进了 // CameraService::connect() ret = (cs.get()-&gt;*fnConnectService)(cl, cameraId, clientPackageName, clientUid, clientPid, /*out*/ &amp;c-&gt;mCamera); &#125; ... return c;&#125;step 3：// CameraService::connec()构造了一个CameraClient(),又是一个CameraClient，// 但是和上面的ICameraClient没有半毛线关系。只是名字相似,真的是一万个++泥马在奔腾。status_t CameraService::connect(const sp&lt;ICameraClient&gt;&amp; cameraClient, int cameraId, const String16&amp; clientPackageName, int clientUid, /*out*/sp&lt;ICamera&gt;&amp; device) &#123; // CameraService::connect()就做了两件事情 // 初始化Camera里的mCamera和把Camera(参数cameraClient为Camera类型)传给CameraClient // 由上面的分析我们知道CameraClient的构造函数最后会走到CameraService中的Client构造函数 // 所以说，Camera类就是mRemoteCallback client = new CameraClient(this, cameraClient, clientPackageName, cameraId, facing, callingPid, clientUid, getpid()); device = client; return OK;&#125; 所以，使用的c-&gt;notifyCallback调用的是Camera::notifyCallback。123456789101112131415161718// callback from camera servicevoid Camera::notifyCallback(int32_t msgType, int32_t ext1, int32_t ext2)&#123; return CameraBaseT::notifyCallback(msgType, ext1, ext2);&#125;template &lt;typename TCam, typename TCamTraits&gt;void CameraBase&lt;TCam, TCamTraits&gt;::notifyCallback(int32_t msgType, int32_t ext1, int32_t ext2)&#123; sp&lt;TCamListener&gt; listener; &#123; Mutex::Autolock _l(mLock); listener = mListener; &#125; if (listener != NULL) &#123; listener-&gt;notify(msgType, ext1, ext2); &#125;&#125; 这里的mListener是在android_hardware_Camera.cpp被设置，接下来我们进入到JNI层(终于快到Java层了^^)。 5. 消息上报(jni层)首先我们先看一下mListener的设置代码： 1234567static jint android_hardware_Camera_native_setup(...)&#123; sp&lt;Camera&gt; camera; sp&lt;JNICameraContext&gt; context = new MtkJNICameraContext(env, weak_this, clazz, camera); // 设置mListener，类型为MtkJNICameraContext camera-&gt;setListener(context);&#125; 所以listener-&gt;notify调用的是MtkJNICameraContext::notify函数：1234567891011121314void JNICameraContext::notify(int32_t msgType, int32_t ext1, int32_t ext2)&#123; ALOGV(&quot;notify&quot;); ... // 这里的post_event在android_hardware_Camera.cpp中有被定义postEventFromNative() // 所以会调用到frameworks/base/core/java/android/hardware/Camera.java的 // postEventFromNative方法 env-&gt;CallStaticVoidMethod(mCameraJClass, fields.post_event, mCameraJObjectWeak, msgType, ext1, ext2, NULL);&#125;jclass clazz = FindClassOrDie(env, &quot;android/hardware/Camera&quot;);fields.post_event = GetStaticMethodIDOrDie(env, clazz, &quot;postEventFromNative&quot;, &quot;(Ljava/lang/Object;IIILjava/lang/Object;)V&quot;); 那么我们来看一下Camera.java中做了什么操作： 12345678910111213141516171819202122232425262728private static void postEventFromNative(Object camera_ref, int what, int arg1, int arg2, Object obj)&#123; Camera c = (Camera)((WeakReference)camera_ref).get(); if (c == null) return; if (c.mEventHandler != null) &#123; Message m = c.mEventHandler.obtainMessage(what, arg1, arg2, obj); // 这里把hardware层上来的消息发送出去了，在Camera的内部类EventHandler中处理 c.mEventHandler.sendMessage(m); &#125;&#125;private class EventHandler extends Handler &#123; @Override public void handleMessage(Message msg) &#123; case MTK_CAMERA_MSG_EXT_NOTIFY: case MTK_CAMERA_MSG_EXT_NOTIFY_ASD: if (mAsdCallback != null) &#123; // 这里回调到Asd中声明的AsdCallback里 mAsdCallback.onDetected(msg.arg2); &#125; break; .... &#125;&#125; ok，到这里消息在JNI层是如何被处理、上报到framework再到App就结束了。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"Android系统","slug":"Android系统","permalink":"http://yoursite.com/tags/Android系统/"},{"name":"Camera","slug":"Camera","permalink":"http://yoursite.com/tags/Camera/"}]},{"title":"Hello Hexo","slug":"Hello Hexo","date":"2018-01-11T06:34:08.820Z","updated":"2018-01-11T06:47:02.338Z","comments":true,"path":"2018/01/11/Hello Hexo/","link":"","permalink":"http://yoursite.com/2018/01/11/Hello Hexo/","excerpt":"","text":"最近在整理有道笔记的内容，平常都是做伸手党，在互联网各位大神的肩膀上分析/解决问题，于是就想以博客的形式输出一些内容，主要是Android系统源码方面的，希望能在积累沉淀自己的同时，帮助到一些遇到了类似问题的人。可能会偶尔发表自己的一些生活感想，就当是日记记录吧。 作为一个程序员，本着亲自动手的想法，博客当然是想自己搭建了，所以查询了相关资料，折腾了一个上午总算搭建好了。（使用Github + Hexo的方式） 教程链接： Mac Windows Hello Hexo，第一篇章。","categories":[{"name":"Diary","slug":"Diary","permalink":"http://yoursite.com/categories/Diary/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"}]}]}